---
layout: post
title: 📷 머선129 개발 로그 0. 연구 배경/디자인 시안 구상/프로젝트 초기 설정
date: 2022-01-11 03:15:00 +0900
published: true
categories: [projects, ms129]
tags: [project, ms129, react native, expo]
---

지난 2학기에 디자인프로젝트를 수행하기 전에
방학때 진행했던 세미나 복습부터 디자인프로젝트 제안서, 중간보고서, 그리고 중간 연구 과정들도
블로그에 포스팅을 해야겠다고 거창하게 목표를 세웠는데,  
중도 휴학 때문에 중간에 정신이 없었기도 하고
당장 포스팅하기보다 개선 사항 찾아서 학습 돌리기 바쁘다 보니 포스팅을 아예 하지 못했다.  
 
디자인프로젝트가 모두 끝나고 방학을 맞은 이 시점에서
개발 소스를 깃헙에 정리하는 동시에, 프로젝트에서의 애플리케이션 파트를 혼자 구현하면서  
어떠한 이슈들을 직면했고 어떤 접근으로 해결했는지 등을 다시 포스트로 남겨놓으면 좋겠다 하는 생각이 들었다.  
 
어차피 현재 API 서버 연결 부분을 제외하고 80~90% 정도 애플리케이션이 구현된 단계에서
디자인프로젝트가 끝났다는 이유로 애정 담긴 프로젝트를 던져 버리고 싶지 않았기도 하고...  
이후 시간 날 때마다 개발을 이어나가 꼭 출시하고자 하는 게 올 해 목표에 있기 때문에
우선 지금까지의 과정을 remind 차원에서 포스팅하고
앞으로 이어서 개발하는 과정 또한 쭉 포스팅해 나가면 될 것 같다.  
첫 포스트는 주제 선택 동기, 앱 아이디어 구체화, 그리고 어떤 개발 환경을 구축했는지부터 정리해 보려고 한다.  

## **📋 1. 연구 배경**

### **🙂 A. 디자인프로젝트를 수강한 계기**

주제를 선정하게 된 배경을 설명하려면 내가 디자인프로젝트를 하게 된 계기부터 시작할 필요가 있다.  
 
원래 디프는 전자공학과 심화전공, 그니까 단일 전공으로 졸업하게 되는 경우
필수 설계 학점을 채우기 위해 들어야 하는 과목이었다.  
그래서 컴퓨터공학을 다전공하는 나는 디자인프로젝트가 필수가 아니었고,
굳이 다른 친구들이 말리지 않아도 애초에 이수할 생각조차 없었다.  
 
그러다가 2021년도 1학기에 어느 교수님께서 진행하시는 마이크로프로세서 수업을 듣고 나서
교수님의 열정, 말씀해주시는 공학자로써의 태도 등 교수님께 반해버리고
디자인프로젝트를 교수님이 계시는 영상처리 연구실에서 진행하기로 결심했다.  
 
별개로 이맘때 쯤에 개인 프로젝트를 진행해보고 싶은 생각이 있었는데
디자인프로젝트를 통해 맘에 드는 주제를 선정하고 그 프로젝트를 3~4개월 간 진행하면서
교수님과 석사 분들의 피드백을 받고 연구실 서버 등 리소스를 사용할 수 있는 환경이
어떻게 보면 너무 좋은 프로젝트 환경이 아닌가 싶어서 결과적으로 디자인프로젝트를 수강 신청하게 됐다.  

### **🔥 B. 주제 선정 동기**

재작년, 작년 우리 연구실에서 진행한 주제들을 확인해 봤을 때
`영상처리를 통한 축구 오프사이드 판독기`나 `시각 장애인을 위한 점자 블록 인식기` 등이 있었다.
보통 전자공학과 졸업 작품이라는 특징 때문에 학술제에 출품되는 주제들이
반도체나 회로, 통신 관련 연구주제들이 많은데,
이런 점에서 영상처리, 딥러닝 기술을 활용하면서도 실제 결과물이 와닿는 주제를 하기로 마음먹었다.

팀원은 나를 포함해 전부터 친했던 친구들 3명으로 구성됐는데,
처음에 제안했던 `블랙박스 영상을 통한 교통사고 과실 비율 판독기`,
`CCTV 영상을 이용한 도서관 자리 점유 판독 시스템` 등은 여러가지 이유로 석사 형들 선에서 리젝당했다.
그 과정에서 GAN, Generative Adversarial Network를 이용한 주제는 어떻겠냐는 피드백이 있었고
최종적으로 개강을 일주일 정도 앞두고 추려진 주제인 `강아지 영상을 통한 감정 분석 애플리케이션`과
`셀카를 이용한 증명사진 생성 애플리케이션` 중 후자를 고르게 됐다.

석사 형들의 조언대로 주제를 선정하면서 크게 고려했던 요인인
"학습에 사용되는 데이터셋의 확보"에 대해서는 AI-Hub에서 제공하는
한국인 안면 데이터셋과 한국인 헤어스타일 데이터셋을 사용하면 해볼만 하지 않을까 생각했고,
세명 중 나를 제외한 두 명은 StarGAN-v2와 StyleGAN을 연구한 모델 개선 방향을,
나는 모델 배포 및 애플리케이션 구현을 중점으로 역할을 배분했다.

## **📋 2. 네이밍 및 스토리텔링 선정**

![img-11](https://user-images.githubusercontent.com/6462456/150996154-cf011a17-4aef-4226-8998-a2e5a082f7c6.jpg)
_Concept Idea Sketching_

애플리케이션의 이름을 정하면서 가장 먼저 기존에 존재하는 카메라 및 사진 애플리케이션들의 이름을 나열했다.  
가장 많이 사용되는 애플리케이션들 중에서는 `B612`, `SODA`, `Ulike`, `SNOW` 등이 있었다.  
이러한 이름들을 보고 난 후엔, 직관적으로 우리 애플리케이션만의 개성을 나타내면서
`머신러닝`, `사진`, `GAN` 처럼 우리 주제를 반영할 수 있는 단어가 포함되면 좋겠다고 생각했다.  
 
주제와 연관 있는 단어들을 연상해 나가는 과정에서 우연히 "머선129" 라는 유행어가 하나 떠올랐다.  
머선129는 보통 사투리로 "무슨 일이야?" 의 의미를 가진 "머선 일이고~~"를
소리나는 대로 뒤의 글자들을 숫자로 치환한 형태의 유행어인데,
엄청 막 핫하고 그런 유행어는 아니지만 종종 쓰이고 광고 배너에도 포함되는 그런 단어였다.  
나는 이 단어의 "머선" 부분에서 "머신러닝"을 연상했고 (?)
전체적인 이름 구조가 "B612"와 비슷하다는 점에서 꽤 괜찮은 느낌의 네이밍이라고 생각했다.  
 
한번 이렇게 생각하자,
"머선129" -> "셀카만 넣었는데 헤어 스타일과 정장 스타일까지 선택한 증명사진이 생긴다구? 머선 일이고~~~~"
...처럼 스토리텔링을 구성해야겠다고 생각이 술술 전개됐다.  
이렇게 애플리케이션 이름을 `머선129 : ms129`로 정했다.  

## **📋 3. 디자인 시안 구상**

![img-14](https://user-images.githubusercontent.com/6462456/150997030-0bf7a6df-6839-46b1-a7ae-d3738fb1e2d5.jpg){: width="220px" class="normal"}
![img-13](https://user-images.githubusercontent.com/6462456/150997053-94ed9246-5811-41d5-bdd6-a7893d4130a5.jpg){: width="220px" class="normal"}
![img-12](https://user-images.githubusercontent.com/6462456/150997057-ae43ebe0-f207-416c-9df4-37d7c70470d0.jpg){: width="220px" class="normal"}

사실 애플리케이션 개발에서 막혔던 시간보다 초기 디자인 컨셉을 정하는 데 시간을 더 많이 썼던 것 같다.  
일러스트레이터는 아예 모르고 포토샵만 조금 다룰 줄 아는 내게 UI/UX 디자인은 맨땅에 헤딩하기 같았다.  
그래도 평소에 유투브 디자인 채널을 보면서 어깨 너머로 익힌 UX 디자인과
dribbble 디자인들을 참고해서 디자인 컨셉을 구성했다.  
 
아이콘 디자인 같은 부분은 네이밍을 마치고 "Face ID가 결합된 형태"로 대충 구상했었는데,
셀카에 정장 이미지를 합성한다는 아이디어에 어울리게 애플 Face ID + 넥타이를 합친 형태로 만들어 봤다.  
 
메인 화면이나 선택 화면은 큰 스크롤뷰로 구성된 형태를 생각하고 디자인했는데,
포토샵으로 디자인 소스들을 배치한 후 Adobe XD와 제플린을 이용해 마진이나 패딩을 설정했다.  
처음에는 내 아이폰 X에서만 테스트하다 보니 고정 픽셀값으로만 설정해 놨는데
친구 11 pro에서 테스트해본 이후로는 Screen width, height를 얻은 후
기기마다 스크린 비율을 반영해서 구성하도록 수정했다.  
_(이 부분은 다음 포스팅에서 다시 정리할 예정)_

## **📋 4. 프로젝트 초기 설정**

어떤 기술로 애플리케이션을 개발해야 할까에 대한 부분은 큰 고민 없이 `React native`로 선택했는데,
가장 크게 고려한 점은 2020년에 스타트업 인턴 도중 한번 다뤄본 경험이 있어서
크게 처음부터 바닥에 부딪히면서 배우지 않아도 될 것이라는 생각에서였다.  
또한, 다뤄봤다고 해도 `TabBar`나 `StackNavigation`으로 스크린 이동 프로토타입만 구현해 봤던 정도라서
이번을 계기로 라이브러리를 이용한 기능까지도 좀 구현해 보고 싶은 생각이 있었다.  

추가적으로, 디자인프로젝트가 9월~12월 초까지 진행되는데
내가 주로 맡은 역할이 애플리케이션 개발이라고 해도
온전히 이것만 진행하는 게 아니고 팀원들과 논문 리딩이나 모델 개선점 파악도 꾸준히 진행하고
중간 보고서, 중간주차 발표 등등 시간을 골고루 써야 하다 보니
최대한 빠르게 크로스플랫폼 개발 도구를 사용해야겠다고 생각한 점도 있었다.  
(`Flutter`도 초반에는 고려했는데, Dart를 새로 배우는 시간을 고려해 상대적으로 익숙한 `React Native`로 가기로 했다)  

### **🧐 A. React-native vs Expo**

+ [What is the difference between Expo and React Native?](https://stackoverflow.com/questions/39170622/what-is-the-difference-between-expo-and-react-native)  
+ [[React Native] Expo CLI와 React Native CLI](https://velog.io/@wook4506/React-Native-Expo-CLI와-React-Native-CLI)

React Native를 써서 애플리케이션을 개발하는 데는 크게 두 가지 방법으로 나눌 수 있다.
하나는 `React Native CLI`를 이용하는 방법이고 다른 하나는 `Expo CLI`를 이용하는 방식이다.  
흔히 전자를 bare React Native라고 표현하고 후자를 Expo라고 부른다.  
두 방식의 차이점이나 장단점은 구글링해 보면 자세한 비교들이 많긴 한데 요약하자면
`Expo CLI`는 개발자가 React Native를 개발하는 데 있어서 여러 편의성과 제약을 동시에 제공해 준다고 볼 수 있다.  

`React Native CLI`를 사용하는 경우 테스트 또한 안드로이드 스튜디오나 Xcode를 이용해서 돌리는 반면
`Expo CLI`는 테스트 기기에 Expo 애플리케이션을 설치하는 것만으로 테스트를 수행할 수 있다.  
반대로 Expo를 사용함으로써 생기는 제한 중에서 대표적으로는
Kakao 로그인 모듈 등의 네이티브 모듈을 사용할 수 없다는 점을 들 수 있다.  

보통 React Native를 처음 다루는 사람들에게 Expo를 이용할 것을 권유하고
좀 더 나아가 네이티브 모듈을 수정하고 좀 더 세밀한 옵션들을 손댈 수 있는 개발자들에게는
`React Native CLI`로 개발할 것을 권유하는 것 같아서, 처음에는 `React Native CLI`로 프로젝트를 초기화했는데
자꾸 프로젝트 설정이라던지 이런 부분들에서 에러가 터져서..  
서너 번 대응을 시도하다가 Expo로 프로젝트를 초기화해 보고 잘 실행되는 걸 보고 나서는
그냥 `Expo CLI`로 개발을 이어 나가자고 생각했다.  
디자인프로젝트 최종 발표 기한 내 프로토타입 구현에서 기본적인 UI나 네비게이션을 빼고 큼지막한 기능들로는
카메라 촬영/앨범 접근/API Fetch 정도만 일단 사용할 생각이었어서.. `Expo CLI`로도 충분하겠다는 생각이 들었다.  
추가로, 만약 개발 도중 필요성을 느낀다면 `expo eject` 명령어로
bare React Native 프로젝트로 확장이 가능했기 때문에 일단 시작해보자고 생각했다.  

### **📦 B. 프로젝트 초기화**

![img-63](https://user-images.githubusercontent.com/6462456/150999331-47f6bab4-f6b0-47bb-b0d3-5c2cf03304e4.png)
_Expo 프로젝트 초기화_

```bash
# install expo-cli
npm install -g expo-cli
```

`node`가 설치되어 있다는 전제 하에, `npm`을 통해 `expo-cli`를 설치해 준다.  
설치가 완료된 후에 `expo init [프로젝트 이름]` 을 통해 프로젝트를 초기화할 수 있으며
보통은 `blank`를 선택해 주면 된다.  
`expo init` 명령어에 `--npm` 이나 `--yarn` 옵션을 따로 줌으로써
어떤 패키지 관리자로 `node module`을 설치할 지 지정할 수 있다.  
명령어를 실행하면 필요한 패키지를 구성하고 초기화하기까지 몇 분 정도 소요된다.  

![img-64](https://user-images.githubusercontent.com/6462456/151000177-34d3d6ba-385f-4409-b434-daaaf7f14d49.png)
![img-65](https://user-images.githubusercontent.com/6462456/151000183-504ee8cf-67e7-44c7-b9b0-da05ffb79cfd.png)

프로젝트 초기화가 끝났다면 `npm start` 명령어를 통해 Metro Bundle 콘솔 웹을 실행할 수 있다.  
콘솔 웹이 띄워졌다면 테스트 기기로 활용할 스마트폰에서 Expo 앱을 설치한 후 (IOS는 Expo Go)
회원가입 - 로그인을 하고 네이티브 카메라 앱으로 저 QR 코드를 찍어 링크로 이동하면 된다.  
이 과정에서 같은 무선 네트워크 상에 있어서 이상 없이 로딩이 가능한 것 같다.  

![img-66](https://user-images.githubusercontent.com/6462456/151000414-9a84c615-99f8-4d0c-b140-c5247d7481be.png){: width="450px"}
![img-67](https://user-images.githubusercontent.com/6462456/151000400-378b9637-afbf-4c16-9c8a-147898345178.png)

위와 같이 흰 배경에 **Open ip App.js to ~...** 문구가 뜨면 프로젝트 초기화가 성공적으로 이루어졌다는 의미이다.  
vscode 등으로 프로젝트를 열고 `App.js` 내용을 수정하면 스크린에 뜬 문구가  
Fast Refresh를 통해 바로 업데이트되는 것을 확인할 수 있다.  
개발하면서 가장 편리했던 기능이다.  

---

이 포스트를 시작으로 앞으로 기록할 내용들은 Expo를 통한 개발 튜토리얼보다는
어떠한 라이브러리를 사용해 기능을 구현했고 어떤 이슈들을 해결했는지 정보 공유 등을 목적으로 하기 때문에
앞으로의 포스트에서는 위처럼 자세하게 매 진행 단계를 기록하는 일은 없을 것 같다.  

만약 Expo를 통해 애플리케이션을 처음 개발해보고자 찾아온 분이 있다면,
구글에 검색하면 좋은 튜토리얼들이 정말 많이 나올 테지만
나는 [노마드 코더 무료 강의](https://nomadcoders.co/react-native-for-beginners)를 추천한다.  
이전에 `React`를 접하지 않고 강의를 듣더라도 어느 정도 중간중간 검색하면서 개념을 보충하면
Expo를 통한 개발에 필요한 Basic step들을 충분히 완수할 수 있을 것이다.  

핵심 기능들에 대한 구현은 다음 포스트부터 이어가기로 😋  